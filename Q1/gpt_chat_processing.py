import time
import openai

def send_prompt_to_chat_gpt(prompt):
    """
    Communicates with the GPT-3.5 Turbo model to generate a response based on the given prompt.
    Args:
        prompt (str): The user's prompt.
    Returns:
        str: The generated response from the GPT-3.5 Turbo model.
    """
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": "Your task is to analyze customer texts with high precision, "
                                                "focusing on understanding and extracting key information, sentiments, and queries. "
                                                "Provide detailed, clear, and concise insights based on the analysis."},
                  {"role": "user", "content": prompt}]
    )
    return response['choices'][0]['message']['content'].strip()


def answers(transactions_list, prompt_question):
    """
    Retrieves answers based on the given transactions list and a prompt question.
    Args:
        transactions_list (list): A list of the mentioned transcripts.
        prompt_question (str): The question or prompt for which answers are sought.

    Returns:
        None, Prints the responses generated by the GPT-3.5 Turbo model.
    """
    counter = 0
    for transcript in transactions_list:
        if counter != 0:
            # a time stop is added using the sleep function.
            # To slow down the error: "the rate limit error:requests per min (RPM): Limit 3, Used 3".
            time.sleep(10)
        counter += 1
        conversation = f"{transcript}\n\n{prompt_question}"
        response = send_prompt_to_chat_gpt(conversation)
        print(f"Transcript {counter}:")
        print(response + "\n")




